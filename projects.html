<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="MLSecOps lab projects and infrastructure builds">
    <meta name="author" content="Richard Spicer">
    <title>Projects | Richard Spicer</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <!-- Site Header -->
        <header class="site-header">
            <h1 class="site-title">richardspicer.io</h1>
            <p class="site-tagline">MLSecOps Engineer</p>
        </header>

        <!-- Navigation -->
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="resources.html">Resources</a></li>
                <li><a href="projects.html" class="active">Projects</a></li>
            </ul>
        </nav>

        <!-- Main Content -->
        <main>
            <h1>Lab Projects</h1>
            
            <p>Production-grade infrastructure and MLSecOps implementations. Documenting what I build as I learn.</p>
            
            <section>
                <h2>2025</h2>
                
                <!-- MLSecOps Lab Infrastructure -->
                <div class="card">
                    <h3>MLSecOps Production Lab</h3>
                    <p class="meta">Deployed 2025 | <span class="badge badge-active">Active</span></p>
                    
                    <p>Enterprise-grade homelab infrastructure for learning ML operations. 3-node Proxmox cluster with network segregation, ZFS storage, and GPU acceleration.</p>
                    
                    <p><strong>Tech Stack:</strong> Proxmox VE, ZFS, Ansible, Terraform, VLANs, Datadog</p>
                    
                    <p><strong>Why it matters:</strong> Production ML requires production infrastructure. This lab demonstrates enterprise architecture at homelab cost.</p>
                    
                    <p><strong>Current Status:</strong></p>
                    <ul>
                        <li>3-node HA cluster operational</li>
                        <li>Zone-based firewall with VLAN segmentation</li>
                        <li>ZFS storage pools with backup strategy</li>
                        <li>Datadog monitoring across all hosts</li>
                        <li>Self-hosted Ollama LLM server</li>
                        <li>GPU development workstation</li>
                    </ul>
                    
                    <p><strong>Links:</strong> <a href="https://github.com/richardspicer/mlsecops-lab">GitHub</a></p>
                    
                    <p><strong>What I'm learning:</strong> How to architect ML infrastructure with security controls—network isolation, access management, monitoring, and operational procedures.</p>
                </div>
                
                <!-- Inference Gateway -->
                <div class="card">
                    <h3>Inference Gateway</h3>
                    <p class="meta">November 2025 | <span class="badge badge-wip">Deployed</span></p>
                    
                    <p>FastAPI authentication and rate limiting layer for self-hosted Ollama LLM server. Built to solve the "anyone can DOS your GPU" problem when you expose inference endpoints.</p>
                    
                    <p><strong>Tech Stack:</strong> Python, FastAPI, Redis, Ollama</p>
                    
                    <p><strong>Current Status:</strong> Code complete and deployed.</p>
                    
                    <p><strong>Activation Criteria:</strong></p>
                    <ul>
                        <li>Multi-user lab access requirements</li>
                        <li>API key-based cost/usage tracking needs</li>
                        <li>Production portfolio demonstration</li>
                        <li>Rate limiting and security policy enforcement</li>
                    </ul>
                    
                    <p><strong>Key Features (When Active):</strong></p>
                    <ul>
                        <li>API key authentication</li>
                        <li>Redis-backed rate limiting (60 req/min per key)</li>
                        <li>Request/response audit logging</li>
                        <li>Datadog metrics integration</li>
                        <li>Health monitoring endpoints</li>
                    </ul>
                    
                    <p><strong>Links:</strong> <a href="https://github.com/richardspicer/mlsecops-lab/tree/main/projects/inference-gateway">GitHub</a></p>
                    
                    <p><strong>What I learned:</strong> Building the gateway taught me how protecting GPU resources differs from traditional API rate limiting—token-based costs vs request-based costs matter for ML workloads.</p>
                </div>
            </section>
            
            <section>
                <h2>What's Next</h2>
                
                <p><strong>December 2025:</strong> Complete Google Cloud ACE certification prep</p>
                
                <p><strong>Q1 2026:</strong></p>
                <ul>
                    <li>Google Cloud ACE certification (exam Feb 2)</li>
                    <li>Deploy sandbox environment (VLAN 50 with pfSense gateway)</li>
                    <li>First technical blog post documenting the MLSecOps learning journey</li>
                </ul>
                
                <p><strong>Future Projects:</strong></p>
                <ul>
                    <li>Local AI assistant with RAG over lab documentation</li>
                    <li>Kubernetes cluster for ML workload orchestration</li>
                    <li>ML model security implementations (adversarial testing, guardrails)</li>
                    <li>Advanced monitoring and observability stack</li>
                </ul>
                
                <p>Every project gets documented as it's deployed. Check back or follow on <a href="https://github.com/richardspicer">GitHub</a> for updates.</p>
            </section>
        </main>

        <!-- Footer -->
        <footer>
            <p>&copy; 2025 Richard Spicer</p>
        </footer>
    </div>
</body>
</html>
